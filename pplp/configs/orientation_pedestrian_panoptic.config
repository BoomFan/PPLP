# Example people config
# For each experiment, copy this config and modify the copy

# This file is a config file for pedestrian training with PPLP method on PANOPTIC dataset.

model_config {
    model_name: 'orient_model'
    checkpoint_name: 'orientation_pedestrian_panoptic'

    input_config {
        bev_depth: 1  # in AVOD it was 6
        img_depth: 3
    }

    rpn_config {
        rpn_proposal_roi_crop_size: 7  # 3
        rpn_fusion_method: 'concat'  # 'concat' or 'mean'
        rpn_train_nms_size: 1024
        rpn_test_nms_size: 1024
        rpn_nms_iou_thresh: 0.8  # 0.8
    }

    avod_config {
        avod_proposal_roi_crop_size: 14  # 7
        avod_positive_selection: 'not_bkg'
        avod_nms_size: 100
        avod_nms_iou_thresh: 0.01
        avod_box_representation: 'box_4ca'  # 'box_3d', 'box_8c', 'box_8co','box_4c', 'box_4ca'(default)
    }

    label_smoothing_epsilon: 0.001
    expand_proposals_xz: 0.0
    # To disable path drop, set both to 1.0
    path_drop_probabilities: [1.0, 1.0]  # [0.9, 0.9]
    train_on_all_samples: False  # False
    eval_all_samples: True

    layers_config {
        bev_feature_extractor {
            bev_vgg {
                vgg_conv1: [2, 32]
                vgg_conv2: [2, 64]
                vgg_conv3: [3, 128]
                vgg_conv4: [3, 256]
                upsampling_multiplier: 4
                l2_weight_decay: 0.0005
            }
        }
        img_feature_extractor {
            img_vgg {
                vgg_conv1: [2, 32]
                vgg_conv2: [2, 64]
                vgg_conv3: [3, 128]
                vgg_conv4: [3, 256]
                upsampling_multiplier: 4
                l2_weight_decay: 0.0005
            }
        }

        rpn_config {
            cls_fc6: 256
            cls_fc7: 256
            reg_fc6: 256
            reg_fc7: 256
            l2_weight_decay: 0.0005
            keep_prob: 1.0  # 0.5
        }
        avod_config {
            # basic_fc_layers {
            #    num_layers: 3
            #    layer_sizes: [2048, 2048, 2048]
            #    keep_prob: 0.5
            #    l2_weight_decay: 0.005
            #    fusion_method: 'concat'  # 'mean' or 'concat', default: 'mean'
            # }
            # or
            # fusion_fc_layers {
            #     num_layers: 3
            #     layer_sizes: [2048, 2048, 2048]
            #     l2_weight_decay: 0.005
            #     keep_prob: 0.5
            #     fusion_method: 'concat'  # 'mean', 'concat', or 'max', default: 'mean'
            #     fusion_type: 'early'  # 'early', 'late', 'deep', default: 'early'
            # }
            # fusion_fc_angle_cls_layers {
            #     num_layers: 3
            #     layer_sizes: [2048, 2048, 2048]
            #     l2_weight_decay: 0.005
            #     keep_prob: 0.5
            #     fusion_method: 'concat'  # 'mean', 'concat', or 'max', default: 'mean'
            #     fusion_type: 'early'  # 'early', 'late', 'deep', default: 'early'
            # }
            # separate_fc_layers {
            #     num_layers: 3
            #     layer_sizes: [2048, 2048, 2048]
            #     l2_weight_decay: 0.005
            #     keep_prob: 0.5
            #     fusion_method: 'concat'  # 'mean', 'concat', or 'max', default: 'mean'
            #     fusion_type: 'early'  # 'early', 'late', 'deep', default: 'early'
            # }
            resnet_fc_layers {
                num_layers: 3  # Not Used!
                layer_sizes: [2048, 2048, 2048]  # Not Used!
                l2_weight_decay: 0.005  # Not Used!
                norm_type: 'BN'  # 'BN' (batch_norm) or 'IN' (instance_norm)
                keep_prob: 1.0  # 0.5
                fusion_method: 'concat'  # Not Used! 'mean', 'concat', or 'max', default: 'mean'
                fusion_type: 'early'  # 'early', 'late', 'deep', default: 'early'
            }
        }
    }

    # Loss function weights
    loss_config {
        cls_loss_weight: 1.0
        reg_loss_weight: 5.0
        ang_loss_weight: 1.0  # 1.0
    }
}

train_config {

    batch_size: 1

    optimizer {
        adam_optimizer {
            learning_rate {
                exponential_decay_learning_rate {
                    initial_learning_rate: 0.0002  # 0.0001
                    decay_steps: 30000
                    decay_factor: 0.8
                }
            }
        }
    }

    overwrite_checkpoints: False  # Set it to False if you want to recover from the last checkpoint

    max_checkpoints_to_keep: 1000
    max_iterations: 310000  # 120000
    checkpoint_interval: 7000  # 10000

    summary_interval: 10
    summary_histograms: True  # True
    summary_img_images: True  # True
    summary_bev_images: True  # True

    allow_gpu_mem_growth: True
}

eval_config {
    eval_interval: 200000  # Only evaluate on the first eval_interval data
    eval_mode: 'val'
    ckpt_indices: -1  # defualt: -1
    evaluate_repeatedly: False  # True, if run  all the checkpoints; False, if run only one checkpoint.

    allow_gpu_mem_growth: True
}

dataset_config {
    name: 'panoptic'  # All lower case

    # dataset_dir: '~/Panoptic/projects/bodypose2dsim/160422_ultimatum1'
    # data_split: 'train'

    data_split_dir: 'training'
    has_labels: True

    cluster_split: 'train'
    classes: ['Pedestrian']
    num_clusters: [1]

    bev_source: 'lidar'
    aug_list: ['']

    panoptic_utils_config {
        area_extents: [-3.99, 3.99, -5.0, 3.0, 0.0, 6.995]
        voxel_size: 0.01
        anchor_strides: [0.5, 0.5]
        density_threshold: 1

        bev_generator {
            slices {
                height_lo: -5.00
                height_hi: 2.00
                num_slices: 1
            }
        }

        mini_batch_config {
            density_threshold: 1

            rpn_config {
                iou_2d_thresholds {
                   neg_iou_lo: 0.0
                   neg_iou_hi: 0.2  # 0.3
                   pos_iou_lo: 0.2  # 0.45
                   pos_iou_hi: 1.0
                }
                # iou_3d_thresholds {
                #     neg_iou_lo: 0.0
                #     neg_iou_hi: 0.1
                #     pos_iou_lo: 0.3
                #     pos_iou_hi: 1.0
                # }

                mini_batch_size: 512  # 512
            }

            avod_config {
                iou_2d_thresholds {
                    neg_iou_lo: 0.0
                    neg_iou_hi: 0.55  # 0.45
                    pos_iou_lo: 0.55  # 0.55
                    pos_iou_hi: 1.0
                }

                mini_batch_size: 1024  # 1024
            }
        }
    }
}
