# Example people config
# For each experiment, copy this config and modify the copy

# This file is a config file for pedestrian training.

model_config {
    model_name: 'avod_3d_model'
    checkpoint_name: 'avod_3d_pedestrian_panoptic'

    input_config {
        bev_depth: 6
        img_depth: 3
        img_dims_h: 720  # 1080
        img_dims_w: 1280  # 1920
    }

    rpn_config {
        rpn_proposal_roi_crop_size: 3
        rpn_fusion_method: 'mean'
        rpn_train_nms_size: 1024  # 1024
        rpn_test_nms_size: 1024
        rpn_nms_iou_thresh: 0.1  # 0.8
    }

    avod_config {
        avod_proposal_roi_crop_size: 7
        avod_positive_selection: 'not_bkg'
        avod_nms_size: 100
        avod_nms_iou_thresh: 0.01
        avod_box_representation: 'box_4ca'
    }

    label_smoothing_epsilon: 0.001
    expand_proposals_xz: 0.0
    # To disable path drop, set both to 1.0
    path_drop_probabilities: [0.9, 0.9]
    train_on_all_samples: False
    eval_all_samples: True

    layers_config {
        bev_feature_extractor {
            bev_vgg {
                vgg_conv1: [2, 32]
                vgg_conv2: [2, 64]
                vgg_conv3: [3, 128]
                vgg_conv4: [3, 256]
                upsampling_multiplier: 4
                l2_weight_decay: 0.0005
            }
        }
        img_feature_extractor {
            img_vgg {
                vgg_conv1: [2, 32]
                vgg_conv2: [2, 64]
                vgg_conv3: [3, 128]
                vgg_conv4: [3, 256]
                upsampling_multiplier: 4
                l2_weight_decay: 0.0005
            }
        }

        rpn_config {
            cls_fc6: 256
            cls_fc7: 256
            reg_fc6: 256
            reg_fc7: 256
            l2_weight_decay: 0.0005
            keep_prob: 0.5
        }
        avod_config {
            # basic_fc_layers {
            #     num_layers: 3
            #     layer_sizes: [2048, 2048, 2048]
            #     l2_weight_decay: 0.005
            #     keep_prob: 0.5
            #     fusion_method: 'mean'  # 'mean' or 'concat'
            # }
            fusion_fc_layers {
                num_layers: 3
                layer_sizes: [2048, 2048, 2048]
                l2_weight_decay: 0.005
                keep_prob: 0.5
                fusion_method: 'mean'  # 'mean', 'concat', or 'max'
                fusion_type: 'early'  # 'early', 'late', 'deep'
            }
        }
    }

    # Loss function weights
    loss_config {
        cls_loss_weight: 1.0
        reg_loss_weight: 5.0
        ang_loss_weight: 1.0
    }
}

train_config {

    batch_size: 1

    optimizer {
        adam_optimizer {  # adam_optimizer(default), momentum_optimizer, rms_prop_optimizer, gradient_descent
            learning_rate {
                exponential_decay_learning_rate {
                    initial_learning_rate: 0.0002  # 0.0001
                    decay_steps: 30000
                    decay_factor: 0.8
                }
            }
        }
    }

    overwrite_checkpoints: False  # False

    max_checkpoints_to_keep: 10000
    max_iterations: 300000 # 120000
    checkpoint_interval: 10000 # 10000

    summary_interval: 10
    summary_histograms: False
    summary_img_images: False
    summary_bev_images: False

    allow_gpu_mem_growth: True
}

eval_config {
    eval_interval: 100000  # The maximum number of samples for each evaluation.
    eval_mode: 'val'
    ckpt_indices: -1  # -1
    evaluate_repeatedly: False  # True, set it to True if you want to run online evaluation for all checkpoints repeatedly

    allow_gpu_mem_growth: True
}

dataset_config {
    name: 'panoptic'

    # dataset_dir: '~/Panoptic/object'
    # data_split: 'train'

    data_split_dir: 'training'
    has_labels: True

    cluster_split: 'train'
    classes: ['Pedestrian']
    num_clusters: [1]

    bev_source: 'lidar'
    aug_list: ['']

    panoptic_utils_config {
        area_extents: [-3.99, 3.99, -1.5, 1.0, 0.0, 6.995]  # For Panoptic, in camera coordinates
        voxel_size: 0.01
        anchor_strides: [0.5, 0.5]
        density_threshold: 1  # 1

        bev_generator {
            slices {
            height_lo: -0.2  # This is the height above the ground, not y value in camera frame(y-axis)
            height_hi: 2.3  # This is the height above the ground, not y value in camera frame(y-axis)
                num_slices: 5
            }
        }

        mini_batch_config {
            density_threshold: 1  # 1

            rpn_config {
                iou_2d_thresholds {
                   neg_iou_lo: 0.0
                   neg_iou_hi: 0.3
                   pos_iou_lo: 0.45
                   pos_iou_hi: 1.0
                }
                # iou_3d_thresholds {
                #     neg_iou_lo: 0.0
                #     neg_iou_hi: 0.1
                #     pos_iou_lo: 0.3
                #     pos_iou_hi: 1.0
                # }

                mini_batch_size: 512
            }

            avod_config {
                iou_2d_thresholds {
                    neg_iou_lo: 0.0
                    neg_iou_hi: 0.45
                    pos_iou_lo: 0.55
                    pos_iou_hi: 1.0
                }

                mini_batch_size: 1024
            }
        }
    }
}
